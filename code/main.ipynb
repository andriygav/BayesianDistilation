{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "main.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "009c77ef4330486e8b715ce6890022ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_987de364026f45cbb21ef3947f3c2d59",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_84a33e7e5fcc49e98ef7e8e4c1092555",
              "IPY_MODEL_6ba4b73fb37248588d1d00c362f35eb0"
            ]
          }
        },
        "987de364026f45cbb21ef3947f3c2d59": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "84a33e7e5fcc49e98ef7e8e4c1092555": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_defbb46f72384e8fa3ae5b446cd2688b",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1000,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1000,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d639c28b56c84869aa4a02ef61ed288a"
          }
        },
        "6ba4b73fb37248588d1d00c362f35eb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c03f161969094dd2bc9cec795918c651",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1000/1000 [06:38&lt;00:00,  2.51it/s, test=0.659]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b99f47dbe95247f18cd048675b34dad2"
          }
        },
        "defbb46f72384e8fa3ae5b446cd2688b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d639c28b56c84869aa4a02ef61ed288a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c03f161969094dd2bc9cec795918c651": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b99f47dbe95247f18cd048675b34dad2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andriygav/BayesianDistilation/blob/master/code/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKxoz2K5Yo1c"
      },
      "source": [
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from tqdm.notebook import tqdm"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q-_0AJ4k6vkX",
        "outputId": "2da5e406-53e7-45e6-d9f4-f53eb027fbe3"
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gFa8XEB6ATP"
      },
      "source": [
        "# Модель"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6SCxl7bUYo1t"
      },
      "source": [
        "class BayesianNetworkFNN(torch.nn.Module):\n",
        "    @property\n",
        "    def device(self):\n",
        "        return next(self.parameters()).device\n",
        "    \n",
        "    def __init__(self, \n",
        "                 input_dim=10, \n",
        "                 output_dim=1, \n",
        "                 layers=[],\n",
        "                 mu_prior=None,\n",
        "                 sigma_prior=None):\n",
        "        r'''\n",
        "        Initialise Neural Network for Bayesian inference\n",
        "\n",
        "        :param input_dim: size of feature space\n",
        "        :type input_dim: int\n",
        "        :param output_dim: size of target space\n",
        "        :type output_dim: int\n",
        "        :param layers: sizes of each layer for fully connected neural network\n",
        "        :type layers: list[int]\n",
        "        :param mu_prior: parameter of prior for :math:`\\mathsf(E)w`\n",
        "        :type mu_prior: array\n",
        "        :param sigma_prior: parameter of prior for :math:`\\mathsf(V)w`\n",
        "        :type sigma_prior: array\n",
        "        '''\n",
        "        super(BayesianNetworkFNN, self).__init__()\n",
        "\n",
        "        layers = [input_dim] + layers + [output_dim]\n",
        "\n",
        "        self.network = torch.nn.Sequential()\n",
        "        for i in range(1, len(layers)):\n",
        "            self.network.add_module('layer{}'.format(i), \n",
        "                                    torch.nn.Linear(layers[i-1], \n",
        "                                                    layers[i]))\n",
        "            if i != len(layers) - 1:\n",
        "                self.network.add_module('relu{}'.format(i), \n",
        "                                        torch.nn.LeakyReLU())\n",
        "        weight = self.get_weight(self.network)\n",
        "        \n",
        "        self.log_sigma_posterior = torch.nn.Parameter(\n",
        "            torch.zeros_like(weight).float(), requires_grad=True)\n",
        "        self.log_sigma_prior = torch.nn.Parameter(\n",
        "            torch.zeros_like(weight).float(), requires_grad=True)\n",
        "        self.mu_prior = torch.nn.Parameter(\n",
        "            weight.data, requires_grad=True)\n",
        "        \n",
        "        if sigma_prior is not None:\n",
        "            self.log_sigma_prior = torch.nn.Parameter(\n",
        "                torch.log(torch.tensor(sigma_prior).float()), requires_grad=True)\n",
        "\n",
        "        if mu_prior is not None:\n",
        "            self.mu_prior = torch.nn.Parameter(\n",
        "                torch.tensor(mu_prior).float(), requires_grad=True)\n",
        "            \n",
        "            self.set_weight(self.network, weight, self.mu_prior.data)\n",
        "\n",
        "        assert len(self.log_sigma_prior) == len(weight), \\\n",
        "          'length of sigma_prior and weight must bu equels but {} != {}'.format(\n",
        "              len(self.log_sigma_prior), len(weight)\n",
        "          )\n",
        "        assert len(self.mu_prior) == len(weight), \\\n",
        "          'length of mu_prior and weight must bu equels but {} != {}'.format(\n",
        "              len(self.mu_prior), len(weight)\n",
        "          )\n",
        "\n",
        "    def posterior_parameters(self):\n",
        "        yield self.log_sigma_posterior\n",
        "        for param in self.network.parameters():\n",
        "            yield param\n",
        "\n",
        "    def prior_parameters(self):\n",
        "        yield self.log_sigma_prior\n",
        "        yield self.mu_prior\n",
        "\n",
        "    @staticmethod  \n",
        "    def set_weight(seq, weight, new_weight):\n",
        "        assert len(weight) == len(new_weight)\n",
        "\n",
        "        bias = 0\n",
        "        for param in seq.parameters():\n",
        "            param_size = torch.tensor(param.size()).prod()\n",
        "            param.data = new_weight[bias:bias+param_size].view_as(param)\n",
        "            \n",
        "            bias += param_size\n",
        "\n",
        "    @property\n",
        "    def weight(self):\n",
        "        return self.get_weight(self.network)\n",
        "\n",
        "    @staticmethod\n",
        "    def get_weight(seq, requires_grad=True):\n",
        "        weight = None\n",
        "        if requires_grad:\n",
        "            parameters = []\n",
        "            for param in seq.parameters():\n",
        "                parameters.append(param.view(-1))\n",
        "\n",
        "            weight = torch.cat(parameters)\n",
        "        else:\n",
        "            with torch.no_grad():\n",
        "                parameters = []\n",
        "                for param in seq.parameters():\n",
        "                    parameters.append(param.view(-1))\n",
        "\n",
        "                weight = torch.cat(parameters)\n",
        "        return weight\n",
        "\n",
        "    def forward(self, x_batch):\n",
        "        r'''\n",
        "        Model inference for one batch\n",
        "\n",
        "        :param x_batch: \n",
        "            input tensor of shape `batch_size` :math:`\\times` `input_dim`\n",
        "        :type x_batch: Tensor\n",
        "        :return: \n",
        "            output tensor of shape `batch_size` :math:`\\times` `output_dim`\n",
        "        :rtype: Tensor\n",
        "        '''\n",
        "\n",
        "        return self.network(x_batch)\n",
        "\n",
        "    def _D_KL_loss(self):\n",
        "        r'''\n",
        "        The method return KL divergence between prior and posterior. \n",
        "        The distributions are assumed to be normal.\n",
        "        '''\n",
        "\n",
        "        mu_posterior = self.weight\n",
        "\n",
        "        D_KL_1 = 0.5*torch.exp(self.log_sigma_posterior \\\n",
        "                               -self.log_sigma_prior).sum()\n",
        "        D_KL_2 = (0.5*torch.exp(-self.log_sigma_prior) \\\n",
        "                     *(self.mu_prior-mu_posterior)**2).sum()\n",
        "        D_KL_3 = 0.5*(self.log_sigma_prior.sum() \\\n",
        "                      - self.log_sigma_posterior.sum())\n",
        "        D_KL_4 = -1*0.5*len(mu_posterior)\n",
        "\n",
        "        return D_KL_1 + D_KL_2 + D_KL_3 + D_KL_4\n",
        "\n",
        "    def loss(self, likelihood, alpha=1.):\n",
        "        r'''\n",
        "        Compute completed loss for bayesian model.\n",
        "        :param likelihood: data likelihood\n",
        "        :type likelihood: Tensor\n",
        "        '''\n",
        "        return alpha*self._D_KL_loss() - likelihood"
      ],
      "execution_count": 368,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z_77Efec6BnU"
      },
      "source": [
        "# Данные"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3NKIE-p4n4vl"
      },
      "source": [
        "np.random.seed(0)\n",
        "\n",
        "l = 1024\n",
        "n = 10\n",
        "X = np.random.randn(l, n)\n",
        "w = np.random.randn(n)\n",
        "\n",
        "y = X@w + 0.1*np.random.randn(l)"
      ],
      "execution_count": 369,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoHLBnML5CyR"
      },
      "source": [
        "X_train_tr = torch.tensor(X[:900]).float()\n",
        "X_test_tr = torch.tensor(X[900:]).float()\n",
        "\n",
        "y_train_tr = torch.tensor(y[:900]).view(-1, 1).float()\n",
        "y_test_tr = torch.tensor(y[900:]).view(-1, 1).float()\n"
      ],
      "execution_count": 370,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y3Euwip85DSi"
      },
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(X_train_tr, y_train_tr)\n",
        "test_dataset = torch.utils.data.TensorDataset(X_test_tr, y_test_tr)"
      ],
      "execution_count": 371,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7LZuhE15byp"
      },
      "source": [
        "def test(model, dataset, batch_size = 128):\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, pin_memory=True)\n",
        "\n",
        "    real = []\n",
        "    pred = []\n",
        "    for x_batch, y_batch in dataloader:\n",
        "        x_batch = x_batch.to(model.device)\n",
        "        y_batch = y_batch.to(model.device)\n",
        "        output = model(x_batch)\n",
        "\n",
        "        real += y_batch.view(-1).detach().cpu().numpy().tolist()\n",
        "        pred += output.view(-1).detach().cpu().numpy().tolist()\n",
        "\n",
        "    return ((np.array(real) - np.array(pred))**2).mean()"
      ],
      "execution_count": 372,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5eBASOqfjiK7"
      },
      "source": [
        "model = BayesianNetworkFNN()\n",
        "_ = model.to(device)"
      ],
      "execution_count": 382,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GadW2mav7aOn"
      },
      "source": [
        "lr=0.001\n",
        "optimiser_posterior = torch.optim.Adam(model.posterior_parameters(), lr=lr)\n",
        "optimiser_prior = torch.optim.Adam(model.prior_parameters(), lr=0.01*lr)\n",
        "loss_function = torch.nn.MSELoss()"
      ],
      "execution_count": 383,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lFPT6sIJ6lH1",
        "outputId": "46176503-1edd-4282-bd18-b7a87277cedc"
      },
      "source": [
        "test(model, train_dataset)"
      ],
      "execution_count": 384,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "17.00112491541768"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 384
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "009c77ef4330486e8b715ce6890022ac",
            "987de364026f45cbb21ef3947f3c2d59",
            "84a33e7e5fcc49e98ef7e8e4c1092555",
            "6ba4b73fb37248588d1d00c362f35eb0",
            "defbb46f72384e8fa3ae5b446cd2688b",
            "d639c28b56c84869aa4a02ef61ed288a",
            "c03f161969094dd2bc9cec795918c651",
            "b99f47dbe95247f18cd048675b34dad2"
          ]
        },
        "id": "3dMZ64fQ6_Zl",
        "outputId": "ea3dac34-59f7-48cb-b4ee-f72ad7cb3ea1"
      },
      "source": [
        "dataloader = torch.utils.data.DataLoader(train_dataset, \n",
        "                                         batch_size=8, \n",
        "                                         pin_memory=True, \n",
        "                                         shuffle=True)\n",
        "\n",
        "iterator = tqdm(range(1000))\n",
        "for epoch in iterator:\n",
        "    total_loss = 0\n",
        "    for x_batch, y_batch in dataloader:\n",
        "        x_batch = x_batch.to(model.device)\n",
        "        y_batch = y_batch.to(model.device)\n",
        "\n",
        "        optimiser_posterior.zero_grad()\n",
        "        output = model(x_batch)\n",
        "\n",
        "        likelihood = -1*loss_function(output, y_batch)/len(x_batch)\n",
        "        loss = model.loss(likelihood)\n",
        "\n",
        "        loss.backward()\n",
        "        optimiser_posterior.step()\n",
        "\n",
        "\n",
        "        optimiser_prior.zero_grad()\n",
        "        output = model(x_batch)\n",
        "\n",
        "        likelihood = -1*loss_function(output, y_batch)/len(x_batch)\n",
        "        loss = model.loss(likelihood)\n",
        "\n",
        "        loss.backward()\n",
        "        optimiser_prior.step()\n",
        "\n",
        "\n",
        "    iterator.set_postfix({'test': test(model, test_dataset)})"
      ],
      "execution_count": 390,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "009c77ef4330486e8b715ce6890022ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=1000.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNBWXoh67-b7",
        "outputId": "a0ae28c8-71aa-4e35-d47e-ffb0495f1f19"
      },
      "source": [
        "test(model, train_dataset), test(model, test_dataset)"
      ],
      "execution_count": 391,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.6924054174011397, 0.6591168450820817)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 391
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "knwUI2H5-lQy",
        "outputId": "38e2e339-bf72-45c2-b2ae-dd2ef45dfae1"
      },
      "source": [
        "model._D_KL_loss()"
      ],
      "execution_count": 392,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.0807, device='cuda:0', grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 392
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtPlZXGWIhRm",
        "outputId": "39bc4f81-ea9b-4fef-b64b-5fb2b50a33b9"
      },
      "source": [
        "likelihood"
      ],
      "execution_count": 393,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(-0.0162, device='cuda:0', grad_fn=<DivBackward0>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 393
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IubrW0TtIvMr",
        "outputId": "d0cfe9c6-4d9a-4b23-c08c-1b1d31892ee3"
      },
      "source": [
        "model.log_sigma_prior"
      ],
      "execution_count": 395,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Parameter containing:\n",
              "tensor([0.8753, 1.3614, 0.5844, 0.5627, 0.8744, 1.3111, 0.5383, 1.1906, 1.3039,\n",
              "        1.2961, 0.5340], device='cuda:0', requires_grad=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 395
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ocCTzdJNQ2Dm"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}